# -*- coding: utf-8 -*-
"""Topic-Modeling-with-NMF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fw5Ngd4M_TuW14Z5-qhG79aZaWKoVQmt
"""

# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF
from sklearn.preprocessing import normalize

# Dataset
documents = [
    "Python programming is used for web development and data analysis.",
    "Data science involves statistics, machine learning, and data mining.",
    "Soccer is a popular sport played worldwide, with teams in many countries.",
    "The stock market fluctuates with the economy and government policies.",
    "Healthy eating includes vegetables, fruits, and whole grains.",
    "The tech industry is constantly evolving with new advancements in AI and cloud computing.",
    "Running and swimming are good cardiovascular exercises.",
    "Apple's iPhone is one of the leading smartphones in the world.",
    "Football matches attract millions of viewers on television.",
    "AI algorithms are being use to automate tasks in various industries."
]

# Step 1: Preprocess and vectorize the documents using TF-IDF

vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)    # Limit to top 1000 features
tfidf_matrix = vectorizer.fit_transform(documents)

# Step 2: Apply NMF for Topic Modeling

n_topics = 3
nmf_model = NMF(n_components=n_topics, random_state=42)
W = nmf_model.fit_transform(tfidf_matrix)    # Document-topic matrix
H = nmf_model.components_    # Topic-term matrix

# Step 3: Display the topics and their keywords

feature_names = vectorizer.get_feature_names_out()

def display_topics(H, feature_names, num_top_words):
    for topic_idx, topic in enumerate(H):
      print(f"Topic #{topic_idx + 1}:")
      print(", ".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))
      print("\n")

print("Top words per topic:")
display_topics(H, feature_names, num_top_words = 5)

# Step 4: Assign dominant topics to documents

doc_topics = np.argmax(W, axis=1)
df = pd.DataFrame({'Document': documents, 'Dominant Topic': doc_topics + 1})  # +1 to make topics 1

print("\nDocuments and their dominant topics:")

df

# Step 5: Test with a new document

new_document = ["AI and machine learning are transforming the tech industry."]
new_tfidf = vectorizer.transform(new_document)
new_topic_distribution = nmf_model.transform(new_tfidf)
predicted_topic = np.argmax(new_topic_distribution) + 1

print(f"\nNew document: {new_document[0]}")
print(f"Predicted topic: Topic #{predicted_topic}")